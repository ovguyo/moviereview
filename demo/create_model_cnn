# -*- coding: utf-8 -*-
"""
Created on Thu Dec 21 19:05:19 2017

@author: Övgü
"""

import numpy as np
import seaborn as sn
import pandas as pd
from keras.datasets import imdb
from keras.models import Sequential
from keras.layers import Dense
from keras.layers import Conv1D, Flatten, Dropout, MaxPooling1D
from keras.layers import Embedding
from keras.preprocessing import sequence
import matplotlib.pyplot as plt

np.random.seed(7)

# load the dataset but only keep the top 5000 words
top_words = 5000
(X_train, y_train), (X_test, y_test) = imdb.load_data(num_words=top_words)

#Padding the sequences to the same length
max_length = 500
X_train = sequence.pad_sequences(X_train, maxlen = max_length)
X_test = sequence.pad_sequences(X_test, maxlen = max_length)

#Word Embedding
embedding_vector_length=32
def build_model():
    model = Sequential()
    model.add(Embedding(top_words, embedding_vector_length, input_length=max_length))
    
    #CNN Model
    model.add(Conv1D(32, kernel_size= 3, padding= 'same', input_shape=(max_length, embedding_vector_length)))
    model.add(Conv1D(32, kernel_size= 3, padding= 'same'))
    model.add(MaxPooling1D(pool_size=2))
    model.add(Conv1D(16, kernel_size= 3, padding= 'same'))
    model.add(MaxPooling1D(pool_size=2))
    model.add(Conv1D(16, kernel_size= 3, padding= 'same'))
    model.add(MaxPooling1D(pool_size=2))
    model.add(Flatten())
    model.add(Dropout(0.2))
    model.add(Dense(64, activation='sigmoid'))
    model.add(Dropout(0.5))
    model.add(Dense(1, activation='sigmoid'))
    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])
    model.fit(X_train, y_train, epochs=3, batch_size=32)
    return model

model1=build_model()

model_json = model1.to_json()
with open("model_cnn.json", "w") as json_file:
    json_file.write(model_json)
# serialize weights to HDF5
model1.save_weights("model_cnn.h5")
print("Saved model to disk")
